{"cells":[{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"skip"}},"source":["# Install and import Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"slideshow":{"slide_type":"subslide"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in c:\\users\\maaas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.3.1)\n","Collecting pip\n","  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n","Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n","   ---------------------------------------- 2.1/2.1 MB 294.1 kB/s eta 0:00:00\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.3.1\n","    Uninstalling pip-23.3.1:\n","      Successfully uninstalled pip-23.3.1\n","Successfully installed pip-24.0\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/8a/6a/19e9fe04fca059ccf770861c7d5721ab4c2aebc539889e97c7977528a53b/pip-24.0-py3-none-any.whl.metadata\n"]}],"source":["# pip install --upgrade pip"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import mediapipe as mp\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["mp_drawing = mp.solutions.drawing_utils # Draring helpers\n","mp_holistic = mp.solutions.holistic # Mediapipe solutions"]},{"cell_type":"markdown","metadata":{},"source":["# Make Some Detections"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyautogui\n","  Using cached PyAutoGUI-0.9.54.tar.gz (61 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Collecting pymsgbox (from pyautogui)\n","  Using cached PyMsgBox-1.0.9.tar.gz (18 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Collecting pytweening>=1.0.4 (from pyautogui)\n","  Using cached pytweening-1.2.0.tar.gz (171 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting pyscreeze>=0.1.21 (from pyautogui)\n","  Using cached PyScreeze-0.1.30.tar.gz (27 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Collecting pygetwindow>=0.0.5 (from pyautogui)\n","  Using cached PyGetWindow-0.0.9.tar.gz (9.7 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting mouseinfo (from pyautogui)\n","  Using cached MouseInfo-0.1.3.tar.gz (10 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting pyrect (from pygetwindow>=0.0.5->pyautogui)\n","  Using cached PyRect-0.2.0.tar.gz (17 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: Pillow>=9.3.0 in c:\\users\\maaas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (9.5.0)\n","Collecting pyperclip (from mouseinfo->pyautogui)\n","  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, pytweening, mouseinfo, pymsgbox, pyperclip, pyrect\n","  Building wheel for pyautogui (pyproject.toml): started\n","  Building wheel for pyautogui (pyproject.toml): finished with status 'done'\n","  Created wheel for pyautogui: filename=PyAutoGUI-0.9.54-py3-none-any.whl size=37596 sha256=d0e0e75e300b36f16709d205fd6075e220e261996c290b74ee0cd1b04ad475c5\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\95\\dc\\b1\\fe122b791e0db8bf439a0e6e1d2628e48f10bf430cae13521b\n","  Building wheel for pygetwindow (setup.py): started\n","  Building wheel for pygetwindow (setup.py): finished with status 'done'\n","  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11079 sha256=c0532742cdd43868011a4cf7b401a964db6f2078a48d0835c80cb58b9b1b013b\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\07\\75\\0b\\7ca0b598eb4c21d43ba4bcc78a0538dfcf803a5997da33bc19\n","  Building wheel for pyscreeze (pyproject.toml): started\n","  Building wheel for pyscreeze (pyproject.toml): finished with status 'done'\n","  Created wheel for pyscreeze: filename=PyScreeze-0.1.30-py3-none-any.whl size=14401 sha256=5b97b011604cdf26da5071f4902f33a16c765a696c7c6b4a3ef39145bcae2fe9\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\df\\bc\\15\\d685ca085ca4b11e46e54cc3da4e501a98856c7fea8f604500\n","  Building wheel for pytweening (setup.py): started\n","  Building wheel for pytweening (setup.py): finished with status 'done'\n","  Created wheel for pytweening: filename=pytweening-1.2.0-py3-none-any.whl size=8030 sha256=dd61df2ec7568054061724aac6bf202a5f9f8d36b0baf1814a7dc07ec2ecefaa\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\db\\81\\dc\\0d61a3c9614f288e057ab63924e2a49edbeed4ffc916dcda1e\n","  Building wheel for mouseinfo (setup.py): started\n","  Building wheel for mouseinfo (setup.py): finished with status 'done'\n","  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10906 sha256=8ec0756a961f484c916ab414c44655189d83ddeafcd3f52e33e851989ef8df0a\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\20\\0b\\7f\\939ac9ff785b09951c706150537572c00123412f260a6024f3\n","  Building wheel for pymsgbox (pyproject.toml): started\n","  Building wheel for pymsgbox (pyproject.toml): finished with status 'done'\n","  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7417 sha256=10f194c62eb8fbcdfc629d2aadb0b11773e4d9a1ebd59d65e6b91f2005fb1993\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\85\\92\\63\\e126ee5f33d8f2ed04f96e43ef5df7270a2f331848752e8662\n","  Building wheel for pyperclip (setup.py): started\n","  Building wheel for pyperclip (setup.py): finished with status 'done'\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=f31cd369185fee8bd9f5511b834d1cb042efe64a8364af37df1db411bedae17c\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\70\\bd\\ba\\8ae5c080c895c9360fe6e153acda2dee82527374467eae061b\n","  Building wheel for pyrect (setup.py): started\n","  Building wheel for pyrect (setup.py): finished with status 'done'\n","  Created wheel for pyrect: filename=PyRect-0.2.0-py2.py3-none-any.whl size=11205 sha256=ee5fd754db5e3c43ba147deed92e9bc03251f1e0f1e9d1ea6d092ec6558ee183\n","  Stored in directory: c:\\users\\maaas\\appdata\\local\\pip\\cache\\wheels\\c4\\e9\\fc\\b7a666dd4f9a3168fb44d643079b41d36ddab52f470707e820\n","Successfully built pyautogui pygetwindow pyscreeze pytweening mouseinfo pymsgbox pyperclip pyrect\n","Installing collected packages: pytweening, pyrect, pyperclip, pymsgbox, pyscreeze, pygetwindow, mouseinfo, pyautogui\n","Successfully installed mouseinfo-0.1.3 pyautogui-0.9.54 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.2.0 pyscreeze-0.1.30 pytweening-1.2.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install pyautogui"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","\n","# Initialize VideoCapture\n","cap = cv2.VideoCapture(0)\n","\n","# Initialize holistic model\n","with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    \n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor Feed\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False        \n","        \n","        # Make Detections\n","        results = holistic.process(image)\n","        \n","        # Recolor image back to BGR for rendering\n","        image.flags.writeable = True   \n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # 1. Draw face landmarks\n","        mp.solutions.drawing_utils.draw_landmarks(image, results.face_landmarks, mp.solutions.holistic.FACEMESH_TESSELATION, \n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n","                                                 )\n","        \n","        # 2. Right hand\n","        mp.solutions.drawing_utils.draw_landmarks(image, results.right_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS, \n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                                                 )\n","\n","        # 3. Left Hand\n","        mp.solutions.drawing_utils.draw_landmarks(image, results.left_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS, \n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","                                                 )\n","\n","        # 4. Pose Detections\n","        mp.solutions.drawing_utils.draw_landmarks(image, results.pose_landmarks, mp.solutions.holistic.POSE_CONNECTIONS, \n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n","                                                 mp.solutions.drawing_utils.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","                                                 )\n","                        \n","        cv2.imshow('Raw Webcam Feed', image)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","# Release the VideoCapture and close all OpenCV windows\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{},"source":["Capture landmarks and expoer to csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import csv\n","import os\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["501"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n","num_coords"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["landmarks = ['classes']\n","for val in range(1, num_coords +1):\n","    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["2005"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(landmarks)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('coords.csv', mode='w', newline='') as f:\n","    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    csv_writer.writerow(landmarks)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_name = 'Surprised'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","# Initiate holistic model\n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    \n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor Feed\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False        \n","        \n","        # Make Detections\n","        results = holistic.process(image)\n","        # print(results.face_landmarks)\n","        \n","        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n","        \n","        # Recolor image back to BGR for rendering\n","        image.flags.writeable = True   \n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # 1. Draw face landmarks\n","        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n","                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n","                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n","                                 )\n","        \n","        # 2. Right hand\n","        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                                 )\n","\n","        # 3. Left Hand\n","        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","                                 )\n","\n","        # 4. Pose Detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","                                 )\n","        # Export coordinates\n","        try:\n","            # Extract Pose landmarks\n","            pose = results.pose_landmarks.landmark\n","            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n","            \n","            # Extract Face landmarks\n","            face = results.face_landmarks.landmark\n","            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n","            \n","            # Concate rows\n","            row = pose_row+face_row\n","            \n","            # Append class name \n","            row.insert(0, class_name)\n","            \n","            # Export to CSV\n","            with open('coords.csv', mode='a', newline='') as f:\n","                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","                csv_writer.writerow(row) \n","            \n","        except:\n","            pass\n","                        \n","        cv2.imshow('Raw Webcam Feed', image)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load dataset\n","import pandas as pd\n","import numpy as np\n","df = pd.read_csv('coords.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>classes</th>\n","      <th>x1</th>\n","      <th>y1</th>\n","      <th>z1</th>\n","      <th>v1</th>\n","      <th>x2</th>\n","      <th>y2</th>\n","      <th>z2</th>\n","      <th>v2</th>\n","      <th>x3</th>\n","      <th>...</th>\n","      <th>z499</th>\n","      <th>v499</th>\n","      <th>x500</th>\n","      <th>y500</th>\n","      <th>z500</th>\n","      <th>v500</th>\n","      <th>x501</th>\n","      <th>y501</th>\n","      <th>z501</th>\n","      <th>v501</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Surprised</td>\n","      <td>0.686217</td>\n","      <td>0.564808</td>\n","      <td>-1.120794</td>\n","      <td>0.999684</td>\n","      <td>0.711718</td>\n","      <td>0.525018</td>\n","      <td>-1.066136</td>\n","      <td>0.999501</td>\n","      <td>0.724735</td>\n","      <td>...</td>\n","      <td>-0.004222</td>\n","      <td>0.0</td>\n","      <td>0.742421</td>\n","      <td>0.528974</td>\n","      <td>0.007070</td>\n","      <td>0.0</td>\n","      <td>0.746357</td>\n","      <td>0.526092</td>\n","      <td>0.007088</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Surprised</td>\n","      <td>0.686832</td>\n","      <td>0.568289</td>\n","      <td>-0.956498</td>\n","      <td>0.999592</td>\n","      <td>0.712176</td>\n","      <td>0.525509</td>\n","      <td>-0.903293</td>\n","      <td>0.999397</td>\n","      <td>0.725162</td>\n","      <td>...</td>\n","      <td>-0.003853</td>\n","      <td>0.0</td>\n","      <td>0.743574</td>\n","      <td>0.530140</td>\n","      <td>0.007882</td>\n","      <td>0.0</td>\n","      <td>0.747526</td>\n","      <td>0.527022</td>\n","      <td>0.008007</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Surprised</td>\n","      <td>0.687210</td>\n","      <td>0.568377</td>\n","      <td>-0.982773</td>\n","      <td>0.999586</td>\n","      <td>0.712317</td>\n","      <td>0.524930</td>\n","      <td>-0.928480</td>\n","      <td>0.999382</td>\n","      <td>0.725374</td>\n","      <td>...</td>\n","      <td>-0.004250</td>\n","      <td>0.0</td>\n","      <td>0.743315</td>\n","      <td>0.525971</td>\n","      <td>0.007043</td>\n","      <td>0.0</td>\n","      <td>0.747200</td>\n","      <td>0.522934</td>\n","      <td>0.007100</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows Ã— 2005 columns</p>\n","</div>"],"text/plain":["     classes        x1        y1        z1        v1        x2        y2   \n","0  Surprised  0.686217  0.564808 -1.120794  0.999684  0.711718  0.525018  \\\n","1  Surprised  0.686832  0.568289 -0.956498  0.999592  0.712176  0.525509   \n","2  Surprised  0.687210  0.568377 -0.982773  0.999586  0.712317  0.524930   \n","\n","         z2        v2        x3  ...      z499  v499      x500      y500   \n","0 -1.066136  0.999501  0.724735  ... -0.004222   0.0  0.742421  0.528974  \\\n","1 -0.903293  0.999397  0.725162  ... -0.003853   0.0  0.743574  0.530140   \n","2 -0.928480  0.999382  0.725374  ... -0.004250   0.0  0.743315  0.525971   \n","\n","       z500  v500      x501      y501      z501  v501  \n","0  0.007070   0.0  0.746357  0.526092  0.007088   0.0  \n","1  0.007882   0.0  0.747526  0.527022  0.008007   0.0  \n","2  0.007043   0.0  0.747200  0.522934  0.007100   0.0  \n","\n","[3 rows x 2005 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["<Axes: xlabel='classes'>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["df['classes'].value_counts().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(143, 2005)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = df.drop(['classes'], axis=1)\n","y =df['classes']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xgboost\n","  Using cached xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n","Requirement already satisfied: numpy in c:\\users\\maaas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.24.3)\n","Requirement already satisfied: scipy in c:\\users\\maaas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.11.1)\n","Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n","   ---------------------------------------- 99.8/99.8 MB 381.0 kB/s eta 0:00:00\n","Installing collected packages: xgboost\n","Successfully installed xgboost-2.0.3\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.3.1 -> 24.0\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["pip install xgboost\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression, RidgeClassifier\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import StandardScaler\n","xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68cff5724d78490eb8b4fdcd6551e5ae","version_major":2,"version_minor":0},"text/plain":["Training Models:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"This solver needs samples of at least 2 classes in the data, but the data contains only one class: 'Surprised'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Iterate over the pipelines and train models\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo, pipeline \u001b[38;5;129;01min\u001b[39;00m tqdm(pipelines\u001b[38;5;241m.\u001b[39mitems(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Models\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     fit_model[algo] \u001b[38;5;241m=\u001b[39m model\n","File \u001b[1;32mc:\\Users\\maaas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\maaas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Users\\maaas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\maaas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1252\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1250\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1257\u001b[0m     )\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1260\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 'Surprised'"]}],"source":["from tqdm.notebook import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression, RidgeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from sklearn.pipeline import make_pipeline\n","\n","# Assuming xtrain and ytrain are your training data\n","pipelines = {\n","    'lr': make_pipeline(StandardScaler(), LogisticRegression()),\n","    'rc': make_pipeline(StandardScaler(), RidgeClassifier()),\n","#     'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n","#     'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier())\n","}\n","\n","fit_model = {}\n","\n","# Iterate over the pipelines and train models\n","for algo, pipeline in tqdm(pipelines.items(), desc='Training Models'):\n","    model = pipeline.fit(xtrain, ytrain)\n","    fit_model[algo] = model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_model['rc'].predict(xtest)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score # Accuracy metrics \n","import pickle "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for algo, model in fit_model.items():\n","    yhat = model.predict(xtest)\n","    print(algo, accuracy_score(ytest, yhat))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_model['rc'].predict(xtest)[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ytest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('bmodel.pkl', 'wb') as f:\n","    pickle.dump(fit_model['lr'], f)"]},{"cell_type":"markdown","metadata":{},"source":["# Make Detections with Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('bmodel.pkl', 'rb') as f:\n","    model = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","# Initiate holistic model\n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    \n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor Feed\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False        \n","        \n","        # Make Detections\n","        results = holistic.process(image)\n","        # print(results.face_landmarks)\n","        \n","        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n","        \n","        # Recolor image back to BGR for rendering\n","        image.flags.writeable = True   \n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # 1. Draw face landmarks\n","        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n","                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n","                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n","                                 )\n","        \n","        # 2. Right hand\n","        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                                 )\n","\n","        # 3. Left Hand\n","        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","                                 )\n","\n","        # 4. Pose Detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","                                 )\n","        # Export coordinates\n","        try:\n","            # Extract Pose landmarks\n","            pose = results.pose_landmarks.landmark\n","            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n","            \n","            # Extract Face landmarks\n","            face = results.face_landmarks.landmark\n","            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n","            \n","            # Concate rows\n","            row = pose_row+face_row\n","            \n","#             # Append class name \n","#             row.insert(0, class_name)\n","            \n","#             # Export to CSV\n","#             with open('coords.csv', mode='a', newline='') as f:\n","#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","#                 csv_writer.writerow(row) \n","\n","            # Make Detections\n","            X = pd.DataFrame([row])\n","            body_language_class = model.predict(X)[0]\n","            body_language_prob = model.predict_proba(X)[0]\n","            print(body_language_class, body_language_prob)\n","            \n","            # Grab ear coords\n","            coords = tuple(np.multiply(\n","                            np.array(\n","                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n","                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n","                        , [640,480]).astype(int))\n","            \n","            cv2.rectangle(image, \n","                          (coords[0], coords[1]+5), \n","                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n","                          (245, 117, 16), -1)\n","            cv2.putText(image, body_language_class, coords, \n","                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            \n","            # Get status box\n","            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n","            \n","            # Display Class\n","            cv2.putText(image, 'CLASS'\n","                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n","            cv2.putText(image, body_language_class.split(' ')[0]\n","                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            \n","            # Display Probability\n","            cv2.putText(image, 'PROB'\n","                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n","            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n","                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            \n","        except:\n","            pass\n","                        \n","        cv2.imshow('Raw Webcam Feed', image)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cap = cv2.VideoCapture('WIN_20240116_20_59_07_Pro.mp4')\n","# Initiate holistic model\n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    \n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor Feed\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False        \n","        \n","        # Make Detections\n","        results = holistic.process(image)\n","        # print(results.face_landmarks)\n","        \n","        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n","        \n","        # Recolor image back to BGR for rendering\n","        image.flags.writeable = True   \n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # 1. Draw face landmarks\n","        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n","                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n","                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n","                                 )\n","        \n","        # 2. Right hand\n","        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                                 )\n","\n","        # 3. Left Hand\n","        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","                                 )\n","\n","        # 4. Pose Detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n","                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n","                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","                                 )\n","        # Export coordinates\n","        try:\n","            # Extract Pose landmarks\n","            pose = results.pose_landmarks.landmark\n","            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n","            \n","            # Extract Face landmarks\n","            face = results.face_landmarks.landmark\n","            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n","            \n","            # Concate rows\n","            row = pose_row+face_row\n","            \n","#             # Append class name \n","#             row.insert(0, class_name)\n","            \n","#             # Export to CSV\n","#             with open('coords.csv', mode='a', newline='') as f:\n","#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","#                 csv_writer.writerow(row) \n","\n","            # Make Detections\n","            X = pd.DataFrame([row])\n","            body_language_class = model.predict(X)[0]\n","            body_language_prob = model.predict_proba(X)[0]\n","            print(body_language_class, body_language_prob)\n","            \n","            # Grab ear coords\n","            coords = tuple(np.multiply(\n","                            np.array(\n","                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n","                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n","                        , [640,480]).astype(int))\n","            \n","            cv2.rectangle(image, \n","                          (coords[0], coords[1]+5), \n","                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n","                          (245, 117, 16), -1)\n","            cv2.putText(image, body_language_class, coords, \n","                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            \n","            # Get status box\n","            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n","            \n","            # Display Class\n","            cv2.putText(image, 'CLASS'\n","                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n","            cv2.putText(image, body_language_class.split(' ')[0]\n","                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            \n","            # Display Probability\n","            cv2.putText(image, 'PROB'\n","                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n","            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n","                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            \n","        except:\n","            pass\n","                        \n","        cv2.imshow('Raw Webcam Feed', image)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"celltoolbar":"Raw Cell Format","kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
